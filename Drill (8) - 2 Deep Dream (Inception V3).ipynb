{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5장의 컨브넷 필터 시각화 기법과 거의 동일(상위 층에 있는 특정 필터의 활성화를 극대화하기 위해 컨브넷의 입력 경사 상승법을 적용)\n",
    "*특정 필터가 아니라 전체 층의 활성화를 최대화, 한꺼번에 많은 특성을 섞어 시각화\n",
    "*빈 이미지나 노이즈가 조금 있는 입력이 아니라 이미 가지고 있는 이미지를 사용\n",
    "*입력 이미지는 시각 품질을 높이기 위해 여러 다른 스케일(옥타브(octave))로 처리한다.\n",
    "\n",
    "옥타브 : 이미지 크기를 일정한 비율로 연속적으로 줄이거나 늘리는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hongbeom/Workspace/JKP\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "currentPath = os.getcwd()\n",
    "print(currentPath)\n",
    "# os.chdir('/Users/jaekunpark/jupyter_project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hongbeom/.conda/envs/jktest/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 104s 1us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.applications import inception_v3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "K.set_learning_phase(0) # Sets the learning phase to a fixed value. # 여기서는 모델 훈련 X, 모든 훈련 연산 비활성화\n",
    "\n",
    "model = inception_v3.InceptionV3(weights = 'imagenet', include_top = False)\n",
    "\n",
    "# 레이어 가중치 설정\n",
    "layer_contributions = {'mixed2':0.2, 'mixed3':0.3, 'mixed4':2., 'mixed5':1.5,}\n",
    "    # 층 이름과 계수를 매핑한 딕셔너리, 최대화하려는 손실에 층의 활성화가 기여할 양을 선택\n",
    "\n",
    "# 최대화할 손실 정의\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "loss = K.variable(0.)    # Instantiates a variable and returns it.\n",
    "for layer_name in layer_contributions:\n",
    "    coeff = layer_contributions[layer_name]\n",
    "    activation = layer_dict[layer_name].output # 층의 출력을 얻는다.\n",
    "    \n",
    "    scaling = K.prod(K.cast(K.shape(activation), 'float32'))\n",
    "    loss = loss + coeff * K.sum(K.square(activation[:, 2: -2, 2: -2, :])) / scaling\n",
    "    # 층 특성의 L2 Norm 제곱을 손실에 추가(이미지 테두리 제외)\n",
    "    # 층마다 활성화의 크기가 다르기 떄문에 정규화를 위해 전체 원소의 개수를 계산\n",
    "    \n",
    "# prod : Multiplies the values in a tensor, alongside the specified axis.   \n",
    "# cast : Casts a tensor to a different dtype and returns it.\n",
    "# shape : Returns the symbolic shape of a tensor or variable.\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Gradient Ascending Process\n",
    "\n",
    "dream = model.input # 이 텐서는 생성된 이미지 저장\n",
    "grads = K.gradients(loss, dream)[0] # Returns the gradients of loss w.r.t. variables. (손실에 대한 이미지 그래디언트 계산)\n",
    "grads = grads / K.maximum(K.mean(K.abs(grads)), 1e-7) # gradient normalization\n",
    "    # maximum : Element-wise maximum of two tensors.\n",
    "\n",
    "outputs = [loss, grads]\n",
    "fetch_loss_and_grads = K.function([dream], outputs)\n",
    "    # 주어진 입력 이미지에서 손실과 그래디언트 값을 계산할 케라스 Function 객체를 만든다.\n",
    "    # Instantiates a variable and returns it. (input, output)\n",
    "\n",
    "def eval_loss_and_grads(x):\n",
    "    outs = fetch_loss_and_grads([x])\n",
    "    loss_value = outs[0]\n",
    "    grad_values = outs[1]\n",
    "    return loss_value, grad_values\n",
    "\n",
    "def gradient_ascent(x, iterations, step, max_loss = None):\n",
    "    for i in range(iterations):\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        if max_loss is not None and loss_value > max_loss:\n",
    "            break\n",
    "        print('...', i, '번째 손실:', loss_value)\n",
    "        x += step * grad_values\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리할 이미지 크기 (510, 510)\n",
      "... 0 번째 손실: 0.58765143\n",
      "... 1 번째 손실: 0.8211911\n",
      "... 2 번째 손실: 1.1290452\n",
      "... 3 번째 손실: 1.4748727\n",
      "... 4 번째 손실: 1.8278415\n",
      "... 5 번째 손실: 2.1839423\n",
      "... 6 번째 손실: 2.5105157\n",
      "... 7 번째 손실: 2.8496103\n",
      "... 8 번째 손실: 3.1766157\n",
      "... 9 번째 손실: 3.4859707\n",
      "... 10 번째 손실: 3.7593288\n",
      "... 11 번째 손실: 4.051634\n",
      "... 12 번째 손실: 4.3335032\n",
      "... 13 번째 손실: 4.607343\n",
      "... 14 번째 손실: 4.8838506\n",
      "... 15 번째 손실: 5.1382413\n",
      "... 16 번째 손실: 5.3927493\n",
      "... 17 번째 손실: 5.6502147\n",
      "... 18 번째 손실: 5.9209375\n",
      "... 19 번째 손실: 6.1693254\n",
      "... 20 번째 손실: 6.4584503\n",
      "... 21 번째 손실: 6.7511616\n",
      "... 22 번째 손실: 7.06334\n",
      "... 23 번째 손실: 7.432629\n",
      "... 24 번째 손실: 7.842941\n",
      "... 25 번째 손실: 8.369748\n",
      "... 26 번째 손실: 8.863329\n",
      "... 27 번째 손실: 9.631153\n",
      "처리할 이미지 크기 (714, 714)\n",
      "... 0 번째 손실: 1.829312\n",
      "... 1 번째 손실: 3.6219301\n",
      "... 2 번째 손실: 5.747384\n",
      "... 3 번째 손실: 8.731686\n",
      "처리할 이미지 크기 (1000, 1000)\n",
      "... 0 번째 손실: 3.596242\n",
      "... 1 번째 손실: 8.012013\n"
     ]
    }
   ],
   "source": [
    "# Utility Function\n",
    "\n",
    "def resize_img(img, size):\n",
    "    img = np.copy(img)\n",
    "    factors = (1, float(size[0]) / img.shape[1], float(size[1]) / img.shape[2], 1)\n",
    "    return scipy.ndimage.zoom(img, factors, order = 1)\n",
    "\n",
    "def save_img(img, fname):\n",
    "    pil_img = deprocess_image(np.copy(img))\n",
    "    image.save_img(fname, pil_img)\n",
    "    \n",
    "def preprocess_img(image_path): # 사진을 열고 크기를 줄인 뒤, 인셉션 V3가 인식하는 텐서 포맷으로 변환\n",
    "    img = image.load_img(image_path)\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    img = inception_v3.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def deprocess_image(x): # 넘파이 배열을 적절한 이미지 포맷으로 변환하는 유틸리티 함수\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((3, x.shape[2], x.shape[3]))\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    else:\n",
    "        x = x.reshape((x.shape[1], x.shape[2], 3))\n",
    "        \n",
    "    x /= 2.\n",
    "    x += 0.5\n",
    "    x *= 255. \n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "    # inception_v3.preprocess_input 함수에서 수행한 preprocess 과정을 복원 \n",
    "    #(Xception, InceptionResnetV2, MobileNet, NASNet도 동일한 전처리)\n",
    "    # 픽셀 값을 255로 나누어 0~1사이로 만든 후 -0.5, *2를 통해 -1~1사이의 값으로 만든다.\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "# Gradient Ascend in continuous scale\n",
    "\n",
    "step = 0.01 \n",
    "num_octave = 3\n",
    "octave_scale = 1.4\n",
    "iterations = 30\n",
    "\n",
    "max_loss = 10. # 손실이 10보다 커지면 경사 상승법 중지\n",
    "\n",
    "base_image_path = '/home/hongbeom/Workspace/JKP/Boyhood.jpg'\n",
    "\n",
    "img = preprocess_img(base_image_path)\n",
    "\n",
    "original_shape = img.shape[1:3]\n",
    "successive_shapes = [original_shape]\n",
    "for i in range(1, num_octave):\n",
    "    shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n",
    "    successive_shapes.append(shape) # 경사 상승법을 실행할 스케일 크기를 정의한 튜플의 리스트 준비\n",
    "\n",
    "successive_shapes = successive_shapes[::-1] # 이 리스트를 크기순으로 뒤집는다.\n",
    "\n",
    "original_img = np.copy(img)\n",
    "shrunk_original_img = resize_img(img, successive_shapes[0])\n",
    "\n",
    "for shape in successive_shapes:\n",
    "    print('처리할 이미지 크기', shape)\n",
    "    img = resize_img(img, shape) # scale up\n",
    "    img = gradient_ascent(img, iterations = iterations, step = step, max_loss = max_loss)\n",
    "    \n",
    "    upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape) # 작게 줄인 원본 이미지의 스케일 높임\n",
    "    same_size_original = resize_img(original_img, shape) # 이 크기에 해당하는 원본 이미지의 고해상도 버전 계산\n",
    "    lost_detail = same_size_original - upscaled_shrunk_original_img\n",
    "    \n",
    "    img += lost_detail # 손실된 디테일을 딥드림 이미지에 다시 주입\n",
    "    shrunk_original_img = resize_img(original_img, shape)\n",
    "    save_img(img, fname = '/home/hongbeom/Workspace/JKP/dream_at_scale_' + str(shape) + '.png')\n",
    "    \n",
    "save_img(img, fname = '/home/hongbeom/Workspace/JKP/final_picture.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lapack_mkl_info:\n",
      "    libraries = ['mkl_rt', 'pthread']\n",
      "    library_dirs = ['/home/hongbeom/.conda/envs/jktest3/lib']\n",
      "    define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
      "    include_dirs = ['/home/hongbeom/.conda/envs/jktest3/include']\n",
      "lapack_opt_info:\n",
      "    libraries = ['mkl_rt', 'pthread']\n",
      "    library_dirs = ['/home/hongbeom/.conda/envs/jktest3/lib']\n",
      "    define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
      "    include_dirs = ['/home/hongbeom/.conda/envs/jktest3/include']\n",
      "blas_mkl_info:\n",
      "    libraries = ['mkl_rt', 'pthread']\n",
      "    library_dirs = ['/home/hongbeom/.conda/envs/jktest3/lib']\n",
      "    define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
      "    include_dirs = ['/home/hongbeom/.conda/envs/jktest3/include']\n",
      "blas_opt_info:\n",
      "    libraries = ['mkl_rt', 'pthread']\n",
      "    library_dirs = ['/home/hongbeom/.conda/envs/jktest3/lib']\n",
      "    define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
      "    include_dirs = ['/home/hongbeom/.conda/envs/jktest3/include']\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.show_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "먼저 이미지를 처리하기 위한 스케일(octave)리스트를 정의한다. 스케일은 이전 스케일 보다 1.4배 더 크다\n",
    "가장 작은 것에서 가장 큰 스케일까지 연속적인 각 단계에서 정의한 손실이 최대화되도록 경사 상승법을 수행.\n",
    "경사 상승법이 실행된 후 이미지 크기를 40%증가. \n",
    "\n",
    "예를 들어 350*350 크기의 원본 이미지를 178*178 크기로 줄여서 시작한다.\n",
    "그 다음 40%씩 두 번 늘려서 178*178, 250*250, 350*350 크기에서 총 세 번 딥드립을 수행\n",
    "\n",
    "스케일을 연속적으로 증가시키면서(점점 뭉개지거나 픽셀 경계가 나타나므로) 이미지 상세를 많이 잃지 않도록 간단한 기교를 사용\n",
    "스케일을 늘린 후 이미지에 손실된 디테일을 재주입(원본 이미지가 크기를 늘렸을 때 어땠는지 알기 떄문에 가능)\n",
    "작은 이미지 크기 S와 큰 이미지 크기 L이 주어지면 크기 L로 변경된 원본 이미지와 크기 S로 변경된 원본 이미지 사이의 차이를 계산\n",
    "이 차이가 S에서 L로 변경되었을 때 잃어버린 디테일\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
