{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UmOwZ5Mkw4hf"
   },
   "outputs": [],
   "source": [
    "pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25474,
     "status": "ok",
     "timestamp": 1581920165552,
     "user": {
      "displayName": "박제건",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDs6JORCJdehVzcwppEOdmHmnTAGST_PoAuHLXk=s64",
      "userId": "01930663103651943875"
     },
     "user_tz": -540
    },
    "id": "i1RVZXMpxsYK",
    "outputId": "f645aa15-ec3d-479f-ebab-be5bab99391a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3639128,
     "status": "ok",
     "timestamp": 1581923816224,
     "user": {
      "displayName": "박제건",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDs6JORCJdehVzcwppEOdmHmnTAGST_PoAuHLXk=s64",
      "userId": "01930663103651943875"
     },
     "user_tz": -540
    },
    "id": "oqFdUJm1w3ML",
    "outputId": "a993292a-88d9-4cea-b477-1a5f62fb0577"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 3s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "/content\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 16,812,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "conv_base를 동결하기 전 훈련되는 가중치의 수: 30\n",
      "conv_base를 동결한 후 훈련되는 가중치의 수: 4\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1009 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      " 99/100 [============================>.] - ETA: 6s - loss: 0.6148 - binary_accuracy: 0.6864 Epoch 1/100\n",
      "100/100 [==============================] - 1042s 10s/step - loss: 0.6131 - binary_accuracy: 0.6890 - val_loss: 0.5040 - val_binary_accuracy: 0.8130\n",
      "Epoch 2/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.4966 - binary_accuracy: 0.8025Epoch 1/100\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 0.4973 - binary_accuracy: 0.8015 - val_loss: 0.4191 - val_binary_accuracy: 0.8500\n",
      "Epoch 3/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.4290 - binary_accuracy: 0.8298Epoch 1/100\n",
      "100/100 [==============================] - 22s 221ms/step - loss: 0.4308 - binary_accuracy: 0.8285 - val_loss: 0.3667 - val_binary_accuracy: 0.8620\n",
      "Epoch 4/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.4000 - binary_accuracy: 0.8444Epoch 1/100\n",
      "100/100 [==============================] - 22s 220ms/step - loss: 0.3986 - binary_accuracy: 0.8450 - val_loss: 0.3371 - val_binary_accuracy: 0.8710\n",
      "Epoch 5/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.3643 - binary_accuracy: 0.8606Epoch 1/100\n",
      "100/100 [==============================] - 22s 223ms/step - loss: 0.3636 - binary_accuracy: 0.8605 - val_loss: 0.3146 - val_binary_accuracy: 0.8790\n",
      "Epoch 6/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.3414 - binary_accuracy: 0.8621Epoch 1/100\n",
      "100/100 [==============================] - 22s 220ms/step - loss: 0.3415 - binary_accuracy: 0.8625 - val_loss: 0.2990 - val_binary_accuracy: 0.8790\n",
      "Epoch 7/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.3254 - binary_accuracy: 0.8768Epoch 1/100\n",
      "100/100 [==============================] - 22s 218ms/step - loss: 0.3251 - binary_accuracy: 0.8775 - val_loss: 0.2874 - val_binary_accuracy: 0.8830\n",
      "Epoch 8/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.3065 - binary_accuracy: 0.8753Epoch 1/100\n",
      "100/100 [==============================] - 22s 219ms/step - loss: 0.3091 - binary_accuracy: 0.8740 - val_loss: 0.2823 - val_binary_accuracy: 0.8850\n",
      "Epoch 9/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.3076 - binary_accuracy: 0.8697Epoch 1/100\n",
      "100/100 [==============================] - 22s 222ms/step - loss: 0.3073 - binary_accuracy: 0.8700 - val_loss: 0.2711 - val_binary_accuracy: 0.8860\n",
      "Epoch 10/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2992 - binary_accuracy: 0.8667Epoch 1/100\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 0.2979 - binary_accuracy: 0.8680 - val_loss: 0.2662 - val_binary_accuracy: 0.8850\n",
      "Epoch 11/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2874 - binary_accuracy: 0.8859Epoch 1/100\n",
      "100/100 [==============================] - 22s 224ms/step - loss: 0.2876 - binary_accuracy: 0.8850 - val_loss: 0.2631 - val_binary_accuracy: 0.8910\n",
      "Epoch 12/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2857 - binary_accuracy: 0.8894Epoch 1/100\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 0.2870 - binary_accuracy: 0.8880 - val_loss: 0.2588 - val_binary_accuracy: 0.8900\n",
      "Epoch 13/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2747 - binary_accuracy: 0.8828Epoch 1/100\n",
      "100/100 [==============================] - 22s 225ms/step - loss: 0.2736 - binary_accuracy: 0.8840 - val_loss: 0.2565 - val_binary_accuracy: 0.8860\n",
      "Epoch 14/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2733 - binary_accuracy: 0.8869Epoch 1/100\n",
      "100/100 [==============================] - 22s 218ms/step - loss: 0.2720 - binary_accuracy: 0.8875 - val_loss: 0.2510 - val_binary_accuracy: 0.8920\n",
      "Epoch 15/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2580 - binary_accuracy: 0.8995Epoch 1/100\n",
      "100/100 [==============================] - 22s 218ms/step - loss: 0.2583 - binary_accuracy: 0.8995 - val_loss: 0.2479 - val_binary_accuracy: 0.8980\n",
      "Epoch 16/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2552 - binary_accuracy: 0.9056Epoch 1/100\n",
      "100/100 [==============================] - 22s 224ms/step - loss: 0.2539 - binary_accuracy: 0.9065 - val_loss: 0.2469 - val_binary_accuracy: 0.8950\n",
      "Epoch 17/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2445 - binary_accuracy: 0.9061Epoch 1/100\n",
      "100/100 [==============================] - 22s 224ms/step - loss: 0.2464 - binary_accuracy: 0.9050 - val_loss: 0.2470 - val_binary_accuracy: 0.8980\n",
      "Epoch 18/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2523 - binary_accuracy: 0.8970Epoch 1/100\n",
      "100/100 [==============================] - 22s 225ms/step - loss: 0.2515 - binary_accuracy: 0.8975 - val_loss: 0.2431 - val_binary_accuracy: 0.8900\n",
      "Epoch 19/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2485 - binary_accuracy: 0.9010Epoch 1/100\n",
      "100/100 [==============================] - 22s 221ms/step - loss: 0.2488 - binary_accuracy: 0.9015 - val_loss: 0.2415 - val_binary_accuracy: 0.8980\n",
      "Epoch 20/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2515 - binary_accuracy: 0.9101Epoch 1/100\n",
      "100/100 [==============================] - 22s 220ms/step - loss: 0.2515 - binary_accuracy: 0.9100 - val_loss: 0.2517 - val_binary_accuracy: 0.8920\n",
      "Epoch 21/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2427 - binary_accuracy: 0.9010Epoch 1/100\n",
      "100/100 [==============================] - 22s 223ms/step - loss: 0.2437 - binary_accuracy: 0.9010 - val_loss: 0.2393 - val_binary_accuracy: 0.9010\n",
      "Epoch 22/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2419 - binary_accuracy: 0.8960Epoch 1/100\n",
      "100/100 [==============================] - 22s 218ms/step - loss: 0.2409 - binary_accuracy: 0.8960 - val_loss: 0.2472 - val_binary_accuracy: 0.8900\n",
      "Epoch 23/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2384 - binary_accuracy: 0.9051Epoch 1/100\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 0.2398 - binary_accuracy: 0.9045 - val_loss: 0.2427 - val_binary_accuracy: 0.8970\n",
      "Epoch 24/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2306 - binary_accuracy: 0.9081Epoch 1/100\n",
      "100/100 [==============================] - 22s 220ms/step - loss: 0.2295 - binary_accuracy: 0.9090 - val_loss: 0.2370 - val_binary_accuracy: 0.9020\n",
      "Epoch 25/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2391 - binary_accuracy: 0.9076Epoch 1/100\n",
      "100/100 [==============================] - 22s 216ms/step - loss: 0.2379 - binary_accuracy: 0.9085 - val_loss: 0.2435 - val_binary_accuracy: 0.8930\n",
      "Epoch 26/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2359 - binary_accuracy: 0.9056Epoch 1/100\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 0.2370 - binary_accuracy: 0.9055 - val_loss: 0.2360 - val_binary_accuracy: 0.9010\n",
      "Epoch 27/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2267 - binary_accuracy: 0.9152Epoch 1/100\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 0.2259 - binary_accuracy: 0.9155 - val_loss: 0.2418 - val_binary_accuracy: 0.9020\n",
      "Epoch 28/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2322 - binary_accuracy: 0.9111Epoch 1/100\n",
      "100/100 [==============================] - 21s 208ms/step - loss: 0.2318 - binary_accuracy: 0.9110 - val_loss: 0.2385 - val_binary_accuracy: 0.8980\n",
      "Epoch 29/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2162 - binary_accuracy: 0.9152Epoch 1/100\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 0.2168 - binary_accuracy: 0.9150 - val_loss: 0.2368 - val_binary_accuracy: 0.9030\n",
      "Epoch 30/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2199 - binary_accuracy: 0.9167Epoch 1/100\n",
      "100/100 [==============================] - 22s 216ms/step - loss: 0.2205 - binary_accuracy: 0.9165 - val_loss: 0.2338 - val_binary_accuracy: 0.9030\n",
      "Epoch 31/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2172 - binary_accuracy: 0.9071Epoch 1/100\n",
      "100/100 [==============================] - 22s 223ms/step - loss: 0.2170 - binary_accuracy: 0.9065 - val_loss: 0.2374 - val_binary_accuracy: 0.9000\n",
      "Epoch 32/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2210 - binary_accuracy: 0.9081Epoch 1/100\n",
      "100/100 [==============================] - 22s 221ms/step - loss: 0.2201 - binary_accuracy: 0.9085 - val_loss: 0.2326 - val_binary_accuracy: 0.9010\n",
      "Epoch 33/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2105 - binary_accuracy: 0.9152Epoch 1/100\n",
      "100/100 [==============================] - 22s 221ms/step - loss: 0.2121 - binary_accuracy: 0.9140 - val_loss: 0.2314 - val_binary_accuracy: 0.9090\n",
      "Epoch 34/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2166 - binary_accuracy: 0.9182Epoch 1/100\n",
      "100/100 [==============================] - 22s 219ms/step - loss: 0.2184 - binary_accuracy: 0.9165 - val_loss: 0.2306 - val_binary_accuracy: 0.9060\n",
      "Epoch 35/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2044 - binary_accuracy: 0.9192Epoch 1/100\n",
      "100/100 [==============================] - 22s 216ms/step - loss: 0.2043 - binary_accuracy: 0.9195 - val_loss: 0.2317 - val_binary_accuracy: 0.9070\n",
      "Epoch 36/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2059 - binary_accuracy: 0.9202Epoch 1/100\n",
      "100/100 [==============================] - 22s 216ms/step - loss: 0.2059 - binary_accuracy: 0.9200 - val_loss: 0.2328 - val_binary_accuracy: 0.9040\n",
      "Epoch 37/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2121 - binary_accuracy: 0.9101Epoch 1/100\n",
      "100/100 [==============================] - 22s 218ms/step - loss: 0.2110 - binary_accuracy: 0.9105 - val_loss: 0.2320 - val_binary_accuracy: 0.9070\n",
      "Epoch 38/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2085 - binary_accuracy: 0.9172Epoch 1/100\n",
      "100/100 [==============================] - 22s 217ms/step - loss: 0.2087 - binary_accuracy: 0.9170 - val_loss: 0.2314 - val_binary_accuracy: 0.9080\n",
      "Epoch 39/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2010 - binary_accuracy: 0.9192Epoch 1/100\n",
      "100/100 [==============================] - 22s 218ms/step - loss: 0.2009 - binary_accuracy: 0.9195 - val_loss: 0.2305 - val_binary_accuracy: 0.9080\n",
      "Epoch 40/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2045 - binary_accuracy: 0.9247Epoch 1/100\n",
      "100/100 [==============================] - 22s 217ms/step - loss: 0.2091 - binary_accuracy: 0.9220 - val_loss: 0.2315 - val_binary_accuracy: 0.9080\n",
      "Epoch 41/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2015 - binary_accuracy: 0.9237Epoch 1/100\n",
      "100/100 [==============================] - 22s 215ms/step - loss: 0.2017 - binary_accuracy: 0.9240 - val_loss: 0.2358 - val_binary_accuracy: 0.9010\n",
      "Epoch 42/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2051 - binary_accuracy: 0.9212Epoch 1/100\n",
      "100/100 [==============================] - 22s 219ms/step - loss: 0.2044 - binary_accuracy: 0.9210 - val_loss: 0.2323 - val_binary_accuracy: 0.9050\n",
      "Epoch 43/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2011 - binary_accuracy: 0.9192Epoch 1/100\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 0.2001 - binary_accuracy: 0.9200 - val_loss: 0.2316 - val_binary_accuracy: 0.9080\n",
      "Epoch 44/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1994 - binary_accuracy: 0.9227Epoch 1/100\n",
      "100/100 [==============================] - 22s 216ms/step - loss: 0.1997 - binary_accuracy: 0.9225 - val_loss: 0.2306 - val_binary_accuracy: 0.9090\n",
      "Epoch 45/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1959 - binary_accuracy: 0.9237Epoch 1/100\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 0.1956 - binary_accuracy: 0.9240 - val_loss: 0.2321 - val_binary_accuracy: 0.9060\n",
      "Epoch 46/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2035 - binary_accuracy: 0.9182Epoch 1/100\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 0.2033 - binary_accuracy: 0.9185 - val_loss: 0.2297 - val_binary_accuracy: 0.9080\n",
      "Epoch 47/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1977 - binary_accuracy: 0.9187Epoch 1/100\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 0.1975 - binary_accuracy: 0.9195 - val_loss: 0.2306 - val_binary_accuracy: 0.9080\n",
      "Epoch 48/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1981 - binary_accuracy: 0.9227Epoch 1/100\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 0.1968 - binary_accuracy: 0.9230 - val_loss: 0.2302 - val_binary_accuracy: 0.9120\n",
      "Epoch 49/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1910 - binary_accuracy: 0.9278Epoch 1/100\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 0.1916 - binary_accuracy: 0.9275 - val_loss: 0.2319 - val_binary_accuracy: 0.9040\n",
      "Epoch 50/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1883 - binary_accuracy: 0.9212Epoch 1/100\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 0.1892 - binary_accuracy: 0.9205 - val_loss: 0.2313 - val_binary_accuracy: 0.9060\n",
      "Epoch 51/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1971 - binary_accuracy: 0.9268Epoch 1/100\n",
      "100/100 [==============================] - 22s 216ms/step - loss: 0.1964 - binary_accuracy: 0.9270 - val_loss: 0.2306 - val_binary_accuracy: 0.9080\n",
      "Epoch 52/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1890 - binary_accuracy: 0.9222Epoch 1/100\n",
      "100/100 [==============================] - 22s 218ms/step - loss: 0.1886 - binary_accuracy: 0.9225 - val_loss: 0.2305 - val_binary_accuracy: 0.9090\n",
      "Epoch 53/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1853 - binary_accuracy: 0.9212Epoch 1/100\n",
      "100/100 [==============================] - 21s 215ms/step - loss: 0.1849 - binary_accuracy: 0.9215 - val_loss: 0.2305 - val_binary_accuracy: 0.9080\n",
      "Epoch 54/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1911 - binary_accuracy: 0.9242Epoch 1/100\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 0.1902 - binary_accuracy: 0.9245 - val_loss: 0.2302 - val_binary_accuracy: 0.9070\n",
      "Epoch 55/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1876 - binary_accuracy: 0.9278Epoch 1/100\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 0.1863 - binary_accuracy: 0.9285 - val_loss: 0.2299 - val_binary_accuracy: 0.9100\n",
      "Epoch 56/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1795 - binary_accuracy: 0.9298Epoch 1/100\n",
      "100/100 [==============================] - 22s 215ms/step - loss: 0.1806 - binary_accuracy: 0.9290 - val_loss: 0.2306 - val_binary_accuracy: 0.9080\n",
      "Epoch 57/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1761 - binary_accuracy: 0.9308Epoch 1/100\n",
      "100/100 [==============================] - 22s 221ms/step - loss: 0.1753 - binary_accuracy: 0.9310 - val_loss: 0.2302 - val_binary_accuracy: 0.9090\n",
      "Epoch 58/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1782 - binary_accuracy: 0.9278Epoch 1/100\n",
      "100/100 [==============================] - 22s 220ms/step - loss: 0.1803 - binary_accuracy: 0.9265 - val_loss: 0.2326 - val_binary_accuracy: 0.9060\n",
      "Epoch 59/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1774 - binary_accuracy: 0.9369Epoch 1/100\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 0.1775 - binary_accuracy: 0.9370 - val_loss: 0.2319 - val_binary_accuracy: 0.9070\n",
      "Epoch 60/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1812 - binary_accuracy: 0.9283Epoch 1/100\n",
      "100/100 [==============================] - 22s 225ms/step - loss: 0.1806 - binary_accuracy: 0.9290 - val_loss: 0.2325 - val_binary_accuracy: 0.9100\n",
      "Epoch 61/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1748 - binary_accuracy: 0.9348Epoch 1/100\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 0.1756 - binary_accuracy: 0.9345 - val_loss: 0.2325 - val_binary_accuracy: 0.9080\n",
      "Epoch 62/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1774 - binary_accuracy: 0.9323Epoch 1/100\n",
      "100/100 [==============================] - 22s 223ms/step - loss: 0.1764 - binary_accuracy: 0.9330 - val_loss: 0.2327 - val_binary_accuracy: 0.9080\n",
      "Epoch 63/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1783 - binary_accuracy: 0.9328Epoch 1/100\n",
      "100/100 [==============================] - 22s 224ms/step - loss: 0.1783 - binary_accuracy: 0.9320 - val_loss: 0.2314 - val_binary_accuracy: 0.9070\n",
      "Epoch 64/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1736 - binary_accuracy: 0.9379Epoch 1/100\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 0.1733 - binary_accuracy: 0.9380 - val_loss: 0.2328 - val_binary_accuracy: 0.9050\n",
      "Epoch 65/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1733 - binary_accuracy: 0.9374Epoch 1/100\n",
      "100/100 [==============================] - 22s 222ms/step - loss: 0.1747 - binary_accuracy: 0.9370 - val_loss: 0.2320 - val_binary_accuracy: 0.9070\n",
      "Epoch 66/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1703 - binary_accuracy: 0.9359Epoch 1/100\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 0.1704 - binary_accuracy: 0.9355 - val_loss: 0.2319 - val_binary_accuracy: 0.9100\n",
      "Epoch 67/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1744 - binary_accuracy: 0.9323Epoch 1/100\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 0.1743 - binary_accuracy: 0.9320 - val_loss: 0.2375 - val_binary_accuracy: 0.9040\n",
      "Epoch 68/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1701 - binary_accuracy: 0.9343Epoch 1/100\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 0.1698 - binary_accuracy: 0.9345 - val_loss: 0.2328 - val_binary_accuracy: 0.9090\n",
      "Epoch 69/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1658 - binary_accuracy: 0.9354Epoch 1/100\n",
      "100/100 [==============================] - 23s 225ms/step - loss: 0.1650 - binary_accuracy: 0.9360 - val_loss: 0.2333 - val_binary_accuracy: 0.9070\n",
      "Epoch 70/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1603 - binary_accuracy: 0.9364Epoch 1/100\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 0.1592 - binary_accuracy: 0.9370 - val_loss: 0.2393 - val_binary_accuracy: 0.9040\n",
      "Epoch 71/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1777 - binary_accuracy: 0.9318Epoch 1/100\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 0.1769 - binary_accuracy: 0.9325 - val_loss: 0.2349 - val_binary_accuracy: 0.9040\n",
      "Epoch 72/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1666 - binary_accuracy: 0.9359Epoch 1/100\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 0.1671 - binary_accuracy: 0.9350 - val_loss: 0.2333 - val_binary_accuracy: 0.9100\n",
      "Epoch 73/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1646 - binary_accuracy: 0.9389Epoch 1/100\n",
      "100/100 [==============================] - 22s 224ms/step - loss: 0.1649 - binary_accuracy: 0.9385 - val_loss: 0.2334 - val_binary_accuracy: 0.9070\n",
      "Epoch 74/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1648 - binary_accuracy: 0.9374Epoch 1/100\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 0.1657 - binary_accuracy: 0.9370 - val_loss: 0.2359 - val_binary_accuracy: 0.9090\n",
      "Epoch 75/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1715 - binary_accuracy: 0.9374Epoch 1/100\n",
      "100/100 [==============================] - 22s 225ms/step - loss: 0.1727 - binary_accuracy: 0.9370 - val_loss: 0.2346 - val_binary_accuracy: 0.9070\n",
      "Epoch 76/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1600 - binary_accuracy: 0.9399Epoch 1/100\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 0.1592 - binary_accuracy: 0.9405 - val_loss: 0.2337 - val_binary_accuracy: 0.9100\n",
      "Epoch 77/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1740 - binary_accuracy: 0.9338Epoch 1/100\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 0.1735 - binary_accuracy: 0.9340 - val_loss: 0.2372 - val_binary_accuracy: 0.9090\n",
      "Epoch 78/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1690 - binary_accuracy: 0.9364Epoch 1/100\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 0.1686 - binary_accuracy: 0.9365 - val_loss: 0.2325 - val_binary_accuracy: 0.9100\n",
      "Epoch 79/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1665 - binary_accuracy: 0.9374Epoch 1/100\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 0.1654 - binary_accuracy: 0.9380 - val_loss: 0.2319 - val_binary_accuracy: 0.9110\n",
      "Epoch 80/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1623 - binary_accuracy: 0.9359Epoch 1/100\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 0.1631 - binary_accuracy: 0.9355 - val_loss: 0.2332 - val_binary_accuracy: 0.9110\n",
      "Epoch 81/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1598 - binary_accuracy: 0.9333Epoch 1/100\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 0.1589 - binary_accuracy: 0.9340 - val_loss: 0.2322 - val_binary_accuracy: 0.9090\n",
      "Epoch 82/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1601 - binary_accuracy: 0.9374Epoch 1/100\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 0.1598 - binary_accuracy: 0.9375 - val_loss: 0.2345 - val_binary_accuracy: 0.9090\n",
      "Epoch 83/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1630 - binary_accuracy: 0.9364Epoch 1/100\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 0.1625 - binary_accuracy: 0.9365 - val_loss: 0.2309 - val_binary_accuracy: 0.9120\n",
      "Epoch 84/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1604 - binary_accuracy: 0.9364Epoch 1/100\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 0.1597 - binary_accuracy: 0.9365 - val_loss: 0.2327 - val_binary_accuracy: 0.9080\n",
      "Epoch 85/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1598 - binary_accuracy: 0.9379Epoch 1/100\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 0.1597 - binary_accuracy: 0.9380 - val_loss: 0.2456 - val_binary_accuracy: 0.8980\n",
      "Epoch 86/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1531 - binary_accuracy: 0.9429Epoch 1/100\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 0.1542 - binary_accuracy: 0.9425 - val_loss: 0.2310 - val_binary_accuracy: 0.9110\n",
      "Epoch 87/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1552 - binary_accuracy: 0.9384Epoch 1/100\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 0.1553 - binary_accuracy: 0.9380 - val_loss: 0.2311 - val_binary_accuracy: 0.9110\n",
      "Epoch 88/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1545 - binary_accuracy: 0.9409Epoch 1/100\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 0.1547 - binary_accuracy: 0.9410 - val_loss: 0.2407 - val_binary_accuracy: 0.9020\n",
      "Epoch 89/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1661 - binary_accuracy: 0.9379Epoch 1/100\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 0.1648 - binary_accuracy: 0.9385 - val_loss: 0.2315 - val_binary_accuracy: 0.9110\n",
      "Epoch 90/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1502 - binary_accuracy: 0.9444Epoch 1/100\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 0.1495 - binary_accuracy: 0.9450 - val_loss: 0.2325 - val_binary_accuracy: 0.9090\n",
      "Epoch 91/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1483 - binary_accuracy: 0.9480Epoch 1/100\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 0.1490 - binary_accuracy: 0.9465 - val_loss: 0.2327 - val_binary_accuracy: 0.9100\n",
      "Epoch 92/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1544 - binary_accuracy: 0.9399Epoch 1/100\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 0.1543 - binary_accuracy: 0.9400 - val_loss: 0.2354 - val_binary_accuracy: 0.9030\n",
      "Epoch 93/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1478 - binary_accuracy: 0.9419Epoch 1/100\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 0.1508 - binary_accuracy: 0.9410 - val_loss: 0.2340 - val_binary_accuracy: 0.9080\n",
      "Epoch 94/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1392 - binary_accuracy: 0.9500Epoch 1/100\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 0.1383 - binary_accuracy: 0.9505 - val_loss: 0.2366 - val_binary_accuracy: 0.9080\n",
      "Epoch 95/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1438 - binary_accuracy: 0.9490Epoch 1/100\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 0.1436 - binary_accuracy: 0.9485 - val_loss: 0.2415 - val_binary_accuracy: 0.9040\n",
      "Epoch 96/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1505 - binary_accuracy: 0.9444Epoch 1/100\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 0.1502 - binary_accuracy: 0.9450 - val_loss: 0.2354 - val_binary_accuracy: 0.9130\n",
      "Epoch 97/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1502 - binary_accuracy: 0.9449Epoch 1/100\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 0.1508 - binary_accuracy: 0.9450 - val_loss: 0.2341 - val_binary_accuracy: 0.9130\n",
      "Epoch 98/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1508 - binary_accuracy: 0.9409Epoch 1/100\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 0.1509 - binary_accuracy: 0.9410 - val_loss: 0.2339 - val_binary_accuracy: 0.9110\n",
      "Epoch 99/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1458 - binary_accuracy: 0.9455Epoch 1/100\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 0.1452 - binary_accuracy: 0.9460 - val_loss: 0.2349 - val_binary_accuracy: 0.9140\n",
      "Epoch 100/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1593 - binary_accuracy: 0.9389Epoch 1/100\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 0.1588 - binary_accuracy: 0.9390 - val_loss: 0.2373 - val_binary_accuracy: 0.9100\n",
      "test acc: 0.906\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSEQooIuIRIQCuohIRCigi4hExP8HppP0zObeeIQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36min 25s, sys: 1min 45s, total: 38min 10s\n",
      "Wall time: 1h 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights = 'imagenet', include_top = False, input_shape = (150, 150, 3))\n",
    "    # weights : 모델을 초기화할 가중치 체크포인트(checkpoint)를 지정\n",
    "    # include_top : 네트워크의 최상위 완전 연결 분류기를 포함할지 안 할지 지정. 기본값은 ImageNet의 클래스 1000개에 대응되는 완전\n",
    "    # 연결 분류기를 포함. 별도의 (강아지와 고양이 2개의 클래스를 구분하는) 완전 연결 층을 추가하려고 하므로 이를 포함하지 않는다.\n",
    "    # input_shape : 네트워크에 주입할 이미지 텐서의 크기. 이 매개변수는 선택사항. 이 값을 지정하지 않으면 네트워크가 어떤 크기의\n",
    "    # 입력도 처리할 수 있다.\n",
    "    \n",
    "conv_base.summary()\n",
    "\n",
    "currentPath = os.getcwd()\n",
    "print(currentPath)\n",
    "os.chdir('/content/drive/My Drive/Colab Notebooks/jupyter_project/')\n",
    "\n",
    "\n",
    "\n",
    "# 훈련, 검증, 테스트 분할을 위한 디렉터리\n",
    "train_dir = '/content/drive/My Drive/Colab Notebooks/jupyter_project/Datasets/train'\n",
    "\n",
    "validation_dir = '/content/drive/My Drive/Colab Notebooks/jupyter_project/Datasets/validation'\n",
    "\n",
    "test_dir = '/content/drive/My Drive/Colab Notebooks/jupyter_project/Datasets/test'\n",
    "\n",
    "\n",
    "# 훈련용 고양이 사진 디렉터리\n",
    "train_cats_dir = '/content/drive/My Drive/Colab Notebooks/jupyter_project/Datasets/train/cats'\n",
    "\n",
    "# 훈련용 강아지 사진 디렉터리\n",
    "train_dogs_dir = '/content/drive/My Drive/Colab Notebooks/jupyter_project/Datasets/train/dogs'\n",
    "\n",
    "\n",
    "# 검증용 고양이 사진 디렉터리\n",
    "validation_cats_dir = '/content/drive/My Drive/Colab Notebooks/jupyter_project/Datasets/validation/cats'\n",
    "\n",
    "# 검증용 강아지 사진 디렉터리\n",
    "validation_dogs_dir = '/content/drive/My Drive/Colab Notebooks/jupyter_project/Datasets/validation/dogs'\n",
    "\n",
    "# 테스트용 고양이 사진 디렉터리\n",
    "test_cats_dir = '/content/drive/My Drive/Colab Notebooks/jupyter_project/Datasets/test/cats'\n",
    "\n",
    "# 테스트용 강아지 사진 디렉터리\n",
    "test_dogs_dir = '/content/drive/My Drive/Colab Notebooks/jupyter_project/Datasets/test/dogs'\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# 합성곱 기반 층 위에 완전 연결 분류기 추가하기\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation = 'relu'))\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "print('conv_base를 동결하기 전 훈련되는 가중치의 수:', len(model.trainable_weights))\n",
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "print('conv_base를 동결한 후 훈련되는 가중치의 수:', len(model.trainable_weights))\n",
    "    # 추가한 2개의 Dense층 가중치만 훈련(층마다 2개씩 가중치 행렬과 편향 벡터 총 4개의 텐서)\n",
    "    \n",
    "#동결된 합성곱 기반 층과 함께 모델을 end-to-end로 훈련하기\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    zoom_range = 0.1,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (150, 150),\n",
    "    batch_size = 20,\n",
    "    class_mode = 'binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size = (150, 150),\n",
    "    batch_size = 20,\n",
    "    class_mode = 'binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (150, 150),\n",
    "    batch_size = 20,\n",
    "    class_mode = 'binary')\n",
    "\n",
    "model.compile(\n",
    "    loss = 'binary_crossentropy',\n",
    "    optimizer = optimizers.RMSprop(lr = 1e-5),\n",
    "    metrics = ['binary_accuracy'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 100,\n",
    "    epochs = 100,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 50)\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps = 50)\n",
    "print('test acc:', test_acc)\n",
    "\n",
    "\n",
    "# 훈련의 정확도와 손실 그래프\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# 지수 평균 이동(Exponential Moving Averages)로 그래프 그리기\n",
    "def smooth_curve(points, factor = 0.8):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, smooth_curve(acc), 'bo', label = 'Training acc')\n",
    "plt.plot(epochs, smooth_curve(val_acc),  'b', label = 'Validation acc')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, smooth_curve(loss), 'bo', label = 'Training Loss')\n",
    "plt.plot(epochs, smooth_curve(val_loss), 'b', label = 'Validation Loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Drill (5) - 6 Drill (5) - 5 ConvNet + Dropout + Data Augmentation + Pretrained Model(VGG16) + Fine-Tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
